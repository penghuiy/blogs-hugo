---
title: "jenkins被驱逐故障记录"
author: "PengHui Yang"
date: "2019-08-15"
weight: 10
tags: [
  "Kubernetes",
  "jenkins"
]
archives: ["201908"]
---
在一次通过jenkins并行构建大批量服务时，由于cicd集群node节点memory压力过大，导致jenkins master被驱逐，造成开发测试阻塞。为何没有首先驱逐slave节点？本文简单记录下具体分析过程<!--more-->
---

首先，通过 https://www.sunlit.tk/post/kubernetes/02/ 这篇文章的总结已经大致了解了Kubelet的驱逐机制。本篇不再赘述。

### 原因分析

粘上jenkins资源限额配置

```
  resources:
    requests:
      cpu: "1000m"
      memory: "1024Mi"
    limits:
      cpu: "2000m"
      memory: "8192Mi"

JavaOpts: "-Xms4096m -Xmx4096m"
```

据实际观察，实际jenkins用量肯定超过Xms的4G，可以达到6G之多。由于request和limit不一样，所以其Qos类型是Burstable

当节点memory不足时，根据上面的信息，jenkins的master pod和所有slave pod都超过了request，接下来按照Priority优先级排序，默认未设置都为0，接下来按照内存使用量与request的差值。明显，master节点更多，这导致了master节点首先被驱逐。

### 如何避免

从驱逐顺序来看

#### 方案一：设置request（推荐）

增大request和limit一样（当前配置jenkins实际内存使用量肯定会超过request，接近limit），使其成为`guaranteed pods`，slave pod均属于`BestEffort pods`，按照上篇文章的推论（`guaranteed pods在besteffort pods之前绝对不会被驱逐`），jenkins master节点会在最后被驱逐或不被驱逐（在现有配置下一般不会被驱逐）


#### 方案二：设置优先级

该feature在kubernetes v1.8引入，在v1.11版本进入beta状态，并在v1.14版本进入GA阶段

如果超过了request，优先级决定谁最先被kill，默认是0

设置示例
```
apiVersion: v1
kind: PriorityClass
metadata:
  name: high-priority
value: 1000000
globalDefault: false
description: "This priority class should be used for XYZ service pods only."
---
apiVersion: v1
kind: Pod
metadata:
  name: nginx
  labels:
    env: test
spec:
  containers:
  - name: nginx
    image: nginx
    imagePullPolicy: IfNotPresent
  priorityClassName: high-priority
```

从结果看，两种方案实际效果一样，从易操作角度考虑方案一更加适合，也可结合使用。


