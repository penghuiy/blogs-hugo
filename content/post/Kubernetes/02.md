---
title: "如何理解pod驱逐策略"
author: "PengHui Yang"
date: "2019-08-06"
weight: 10
tags: [
  "Kubernetes"
]
archives: ["201908"]
---
Kubernetes集群node资源不是很充足，经常遇到pod被驱逐的情况。kubelet如何去挑选pod，本文进行大致总结<!--more-->
---

## 浅谈pod驱逐

### Kubelet eviction

按照官方文档的说法，当kubelet检测到node资源不足时会对pod进行驱逐。驱逐顺序是：

1. 是否超过request值（`一般来说只有超过request的pod才会被驱逐`）

2. 优先级（未指定priorityClassName则默认是0）

3. 实际使用量与request的差值

由于牵扯到BestEffort、Burstable、Burstable三种pod Qos等级，所以文档中进行了具体说明

```
BestEffort or Burstable Pods whose usage of a starved resource exceeds its request. Such pods are ranked by Priority, and then usage above request.
Guaranteed pods and Burstable pods whose usage is beneath requests are evicted last. Guaranteed Pods are guaranteed only when requests and limits are specified for all the containers and they are equal. Such pods are guaranteed to never be evicted because of another Pod’s resource consumption. If a system daemon (such as kubelet, docker, and journald) is consuming more resources than were reserved via system-reserved or kube-reserved allocations, and the node only has Guaranteed or Burstable Pods using less than requests remaining, then the node must choose to evict such a Pod in order to preserve node stability and to limit the impact of the unexpected consumption to other Pods. In this case, it will choose to evict pods of Lowest Priority first.
```

超过memory request值的BestEffort或者Burstable的pod，按照Priority排序（Priority低的最先被驱逐），相同的则按照超过request的量排序（如果是多个container，则是它们`使用量总和与request总和的差值，差值越大越先被驱逐`）

未超过memory request值的Guaranteed或者Burstable的pod最后被驱逐（Guaranteed pod的定义是Pod里的每个容器都必须有内存CPU的limit和request，而且必须是一样的）。有任何其他类型pod消耗了资源，就意味着这些pod永远不会被驱逐。

由此推断出

1. guaranteed pods在besteffort pods之前绝对不会被驱逐，但可能会在burstable pods之前被驱逐

2. burstable pods可能会在besteffort pods之前被驱逐

如果一个系统后台进程（例如kubelet、docker、journald）消耗了系统预留或者kube预留的很多资源，此时`node上只有Guaranteed或者Burstable的pod`，node会选择驱逐使用量小于request的pod从而保护node稳定性和限制意外消耗对其他pod的影响。这种情况，它会`首先选择驱逐Priority低的pod`。

### Node OOM

另一种情况是由于kubelet默认监测间隔为10s(`通过housekeeping-interval指定`)，这段时间内发生系统OOM，导致由OOM killer对内存进行回收。OOM Killer会通过oom_score(`/proc/<pid>/oom_score`)为每个进程打分，从而决定哪个进程最先被kill。
```
oom_score = 物理内存消耗量占总内存的比例 + oom_score_adj
```

* 物理内存消耗量，主要是三部分，RSS部分，swap file或者swap device上占用的内存情况以及页表占用的内存情况。

* kubelet根据pod Qos等级设置oom_score_adj来控制结果，具体策略是

|Qos	|oom_score_adj|
|------------|--------|
|Guaranteed	|-998|
|BestEffort	|1000|
|Burstable	|min（max（2,1000 - （1000 * memoryRequestBytes）/ machineMemoryCapacityBytes），999）|

`oom_score_adj(/proc/<pid>/oom_score_adj)：用户通过该值来保护某个进程不被杀死或者每次都杀某个进程。其取值范围为-1000到1000。设定成OOM_SCORE_ADJ_MIN（-1000）的话，实际上就是禁止了OOM killer杀死该进程。`

对于磁盘资源，此处不再赘述，详见官方文档：
```
If necessary, kubelet evicts Pods one at a time to reclaim disk when DiskPressure is encountered. If the kubelet is responding to inode starvation, it reclaims inodes by evicting Pods with the lowest quality of service first. If the kubelet is responding to lack of available disk, it ranks Pods within a quality of service that consumes the largest amount of disk and kills those first.
```

附：默认驱逐阈值

* memory.available < 100Mi
* nodefs.available < 10%
* nodefs.inodesFree < 5%
* imagefs.available < 15%


参考文档：

out-of-resource: https://kubernetes.io/docs/tasks/administer-cluster/out-of-resource/

Qos：https://kubernetes.io/docs/tasks/configure-pod-container/quality-service-pod/

Priority：https://kubernetes.io/docs/concepts/configuration/pod-priority-preemption/

OOM机制：https://learning-kernel.readthedocs.io/en/latest/mem-management.html

OOM参数：http://www.wowotech.net/memory_management/oom.html
